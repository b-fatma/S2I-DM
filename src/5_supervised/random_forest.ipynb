{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/b-fatma/S2I-DM/blob/master/src/5_supervised/random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpuAcaiNjBLx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy4FVoKHjHua",
        "outputId": "16463f36-ed24-4824-b28a-ebcc6af9af41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PQT6UPJmeHn",
        "outputId": "c8d7983d-644b-4ae6-d543-0fa14725dfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.12/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.3)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.7.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the data"
      ],
      "metadata": {
        "id": "wAVDZdIhZuEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.read_csv('/content/drive/MyDrive/dm_fire_prediction/feature_engineering/v1/y_train.csv')\n",
        "y_test = pd.read_csv('/content/drive/MyDrive/dm_fire_prediction/feature_engineering/v1/y_test.csv')\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/dm_fire_prediction/feature_engineering/v1/X_test.csv')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/dm_fire_prediction/feature_engineering/v1/X_train.csv')\n",
        "\n",
        "X_test_scaled = pd.read_csv('/content/drive/MyDrive/dm_fire_prediction/feature_engineering/v1/X_test_scaled.csv')\n",
        "X_train_scaled = pd.read_csv('/content/drive/MyDrive/dm_fire_prediction/feature_engineering/v1/X_train_scaled.csv')"
      ],
      "metadata": {
        "id": "Seroi4SKZyhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.squeeze()\n",
        "y_test = y_test.squeeze()"
      ],
      "metadata": {
        "id": "sPM-nsNBauS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "UBimNBq_c0ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Categorical, Real\n",
        "\n",
        "rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
        "\n",
        "search_space = {\n",
        "    'n_estimators': Integer(100, 300),\n",
        "    'max_depth': Integer(10, 30),\n",
        "    'min_samples_split': Integer(2, 10),\n",
        "    'min_samples_leaf': Integer(1, 5),\n",
        "    'max_features': Categorical(['sqrt', 'log2']),\n",
        "    'class_weight': Categorical([None, 'balanced'])\n",
        "}\n",
        "\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=rf,\n",
        "    search_spaces=search_space,\n",
        "    n_iter=30,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    random_state=0,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = bayes_search.best_estimator_\n",
        "print(bayes_search.best_params_)"
      ],
      "metadata": {
        "id": "Sj5dWyaip0RB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9afe330f-3ef0-4f69-9a59-c7978b15da4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "OrderedDict({'class_weight': 'balanced', 'max_depth': 24, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, best_model.predict(X_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwdhAMm6r_3P",
        "outputId": "ccfaeb43-c8b2-4866-ad9b-c6ba766ff470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     38228\n",
            "           1       0.98      1.00      0.99     11469\n",
            "\n",
            "    accuracy                           1.00     49697\n",
            "   macro avg       0.99      1.00      0.99     49697\n",
            "weighted avg       1.00      1.00      1.00     49697\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on the test set"
      ],
      "metadata": {
        "id": "ytjzW3dLRG_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, best_model.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SOkFOYPOE7Z",
        "outputId": "b0f6456d-b3f5-43a2-b76f-78e551f892fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      4248\n",
            "           1       0.90      0.92      0.91      1274\n",
            "\n",
            "    accuracy                           0.96      5522\n",
            "   macro avg       0.94      0.94      0.94      5522\n",
            "weighted avg       0.96      0.96      0.96      5522\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From scratch"
      ],
      "metadata": {
        "id": "bZ4cB98zo1Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(self, n_estimators=100, max_depth=10, min_samples_split=2,\n",
        "                 max_features='sqrt', bootstrap=True, random_state=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_features = max_features\n",
        "        self.bootstrap = bootstrap\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        if self.random_state is not None:\n",
        "            np.random.seed(self.random_state)\n",
        "\n",
        "        self.trees = []\n",
        "        n_samples = X.shape[0]\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            tree = DecisionTree(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                max_features=self._get_max_features(X.shape[1])\n",
        "            )\n",
        "\n",
        "            if self.bootstrap:\n",
        "                indices = np.random.choice(n_samples, n_samples, replace=True)\n",
        "                X_sample = X[indices]\n",
        "                y_sample = y[indices]\n",
        "            else:\n",
        "                X_sample = X\n",
        "                y_sample = y\n",
        "\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "\n",
        "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "        tree_predictions = np.swapaxes(tree_predictions, 0, 1)\n",
        "\n",
        "        predictions = [self._majority_vote(pred) for pred in tree_predictions]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _majority_vote(self, predictions):\n",
        "        return Counter(predictions).most_common(1)[0][0]\n",
        "\n",
        "    def _get_max_features(self, n_features):\n",
        "        if self.max_features == 'sqrt':\n",
        "            return int(np.sqrt(n_features))\n",
        "        elif self.max_features == 'log2':\n",
        "            return int(np.log2(n_features))\n",
        "        elif isinstance(self.max_features, int):\n",
        "            return self.max_features\n",
        "        elif isinstance(self.max_features, float):\n",
        "            return int(self.max_features * n_features)\n",
        "        else:\n",
        "            return n_features\n",
        "\n",
        "\n",
        "class DecisionTreeNode:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None\n",
        "\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=10, min_samples_split=2, max_features=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_features = max_features\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        self.n_features = X.shape[1]\n",
        "        self.root = self._build_tree(X, y, depth=0)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.root is None:\n",
        "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
        "        X = np.array(X)\n",
        "        return np.array([self._predict_single(row, self.root) for row in X])\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        if (\n",
        "            depth >= self.max_depth\n",
        "            or len(np.unique(y)) == 1\n",
        "            or num_samples < self.min_samples_split\n",
        "        ):\n",
        "            return DecisionTreeNode(value=self._most_common_label(y))\n",
        "\n",
        "        feature, threshold = self._best_split(X, y)\n",
        "\n",
        "        if feature is None:\n",
        "            return DecisionTreeNode(value=self._most_common_label(y))\n",
        "\n",
        "        left_idx = X[:, feature] <= threshold\n",
        "        right_idx = X[:, feature] > threshold\n",
        "\n",
        "        if np.sum(left_idx) == 0 or np.sum(right_idx) == 0:\n",
        "            return DecisionTreeNode(value=self._most_common_label(y))\n",
        "\n",
        "        left_child = self._build_tree(X[left_idx], y[left_idx], depth + 1)\n",
        "        right_child = self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
        "\n",
        "        return DecisionTreeNode(\n",
        "            feature=feature,\n",
        "            threshold=threshold,\n",
        "            left=left_child,\n",
        "            right=right_child,\n",
        "        )\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        best_gain = -1\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if self.max_features is not None:\n",
        "            features = np.random.choice(n_features, self.max_features, replace=False)\n",
        "        else:\n",
        "            features = range(n_features)\n",
        "\n",
        "        for feature in features:\n",
        "            feature_values = X[:, feature]\n",
        "            sorted_vals = np.unique(feature_values)\n",
        "\n",
        "            if len(sorted_vals) < 2:\n",
        "                continue\n",
        "\n",
        "            thresholds = (sorted_vals[:-1] + sorted_vals[1:]) / 2\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                left_idx = feature_values <= threshold\n",
        "                right_idx = feature_values > threshold\n",
        "\n",
        "                if np.sum(left_idx) == 0 or np.sum(right_idx) == 0:\n",
        "                    continue\n",
        "\n",
        "                gain = self._information_gain(y, feature_values, threshold)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        counts = Counter(y)\n",
        "        probabilities = [count / len(y) for count in counts.values()]\n",
        "        return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
        "\n",
        "    def _information_gain(self, y, feature_values, threshold):\n",
        "        parent_entropy = self._entropy(y)\n",
        "\n",
        "        left_idx = feature_values <= threshold\n",
        "        right_idx = feature_values > threshold\n",
        "\n",
        "        if np.sum(left_idx) == 0 or np.sum(right_idx) == 0:\n",
        "            return 0\n",
        "\n",
        "        n = len(y)\n",
        "        n_left = np.sum(left_idx)\n",
        "        n_right = np.sum(right_idx)\n",
        "\n",
        "        child_entropy = (n_left / n) * self._entropy(y[left_idx]) + \\\n",
        "                        (n_right / n) * self._entropy(y[right_idx])\n",
        "\n",
        "        return parent_entropy - child_entropy\n",
        "\n",
        "    def _predict_single(self, x, node):\n",
        "        if node.is_leaf_node():\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_single(x, node.left)\n",
        "        else:\n",
        "            return self._predict_single(x, node.right)\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        if len(y) == 0:\n",
        "            return None\n",
        "        return Counter(y).most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "w4dGYZO36rM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import time\n",
        "\n",
        "rf = RandomForest(n_estimators=100, max_depth=20, random_state=42)\n",
        "\n",
        "s_time = time.time()\n",
        "rf.fit(X_train, y_train)\n",
        "print(f\"Training time: {time.time() - s_time:.2f}s\")\n",
        "\n",
        "s_time = time.time()\n",
        "y_pred = rf.predict(X_test)\n",
        "print(f\"Prediction time: {time.time() - s_time:.2f}s\\n\")\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "2hFkgaz06sKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4fa359d-f15c-4553-977a-592f3a9f28ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 32661.58s\n",
            "Prediction time: 2.05s\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      4248\n",
            "           1       0.90      0.90      0.90      1274\n",
            "\n",
            "    accuracy                           0.95      5522\n",
            "   macro avg       0.93      0.93      0.93      5522\n",
            "weighted avg       0.95      0.95      0.95      5522\n",
            "\n",
            "Accuracy: 0.9533\n"
          ]
        }
      ]
    }
  ]
}